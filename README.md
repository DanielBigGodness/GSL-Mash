# GSL-Mash
We will update the dataset soon!!!

# Project Structure
The directory structure of new project looks like this:


    │   README.md
    │   requirements.txt               <- File for installing python dependencies
    │   setup.cfg                      <- Configuration of linters and pytest
    │   test.py                        <- Run testing
    │   train.py                       <- Run training
    │
    ├───configs                        <- Hydra configuration files
    │   │   test.yaml                     <- Main config for testing
    │   │   train.yaml                    <- Main config for training
    │   │
    │   ├───callbacks                  <- Lightning callbacks
    │   │       wandb.yaml                <- Wandb and metrics callbacks
    │   │
    │   ├───datamodule                    
    │   │       partial_text_bert.yaml    <- Partial text-based dataset embedded by BERT configs
    │   │       partial_word_bert.yaml    <- Partial word-based dataset embedded by BERT configs
    │   │
    │   ├───experiment                 <- Experiment configs
    │   │
    │   ├───hparams_search             <- Hyperparameter search configs
    │   │
    │   ├───logger                     <- Logger configs
    │   │
    │   ├───log_dir                    <- Logging directory configs
    │   │
    │   ├───model                      <- Model configs
    │   │
    │   └───trainer                    <- Trainer configs
    │
    ├───data                        <- Project data
    │
    ├───logs                        <- Logs generated by Hydra and PyTorch 
                                       Lightning loggers
    ├───src                         <- Source code
    │   │   testing_pipeline.py
    │   │   training_pipeline.py
    │   │
    │   ├───callbacks
    │   │       wandb_callbacks.py
    │   │
    │   ├───datamodules             <- Lightning datamodules
    │   │
    │   ├───models                  <- Lightning models
    │   │
    │   ├───utils                   <- Utility scripts
    │   │
    │   └───vendor                  <- Third party code that cannot be installed using PIP/Conda
    │
    └───tests                       <- Tests of any kind
        │
        ├───helpers                    <- A couple of testing utilities
        │
        ├───shell                      <- Shell/command based tests
        │
        └───unit                       <- Unit tests


# Installation

You can install environment by anaconda or docker, and then download the dataset.

## Install with anaconda

    # clone project
    git clone https://github.com/DanielBigGodness/GSL-Mash
    cd GSL-Mash

## create conda environment
    conda create -n myenv python=3.8
    conda activate myenv

## install requirements
    pip install -r requirements.txt

# Quickstart
Implement the DL-based model as the LightningModule class. Details refer to Model Implementation. Here the MLP model (pre-configured in our project) is used as an example.

Write a configuration file called simple_model for your model.

     _target_: src.models.mlp.MLP
     data_dir: ${data_dir}/api_mashup
     api_embed_path: embeddings/partial/text_bert_api_embeddings.npy
     mashup_embed_channels: 300
     mlp_output_channels: 300
     lr: 0.001
     weight_decay: 0.00001
     
Write a configuration file called mlp for your experiment.

     # @package _global_
    
     defaults:
         - override /trainer: default.yaml              # use default settings for trainer
         - override /model: mlp.yaml                    # use "mlp" as model
         - override /datamodule: partial_text_bert.yaml # use partial text-based embeddings encoded by BERT
         - override /callbacks: wandb.yaml              # use wandb as the callbacks
         - override /logger: wandb.yaml                 # use wandb as the log framework
    
     seed: 12345
    
     logger:
         wandb:
             name: 'MLP-partial-BERT'
             tags: ['partial', 'BERT']
    
     # Override model parameters
     model:
         api_embed_path: embeddings/partial/text_bert_api_embeddings.npy
         mashup_embed_channels: 768
         mlp_output_channels: 300
         lr: 0.001
Since the project uses wandb as the log framework by default, you will need to have a wandb account and bind the account to the project by executing the following command.

    wandb login
This command needs to be executed only once during the entire development process.

If you do not want to use wandb, you can also choose another log framework. Please refer to LightningModule for how to change it.

run the project.

    python train.py experiment=mlp_new/partial_bert

